=== ESSAY QUESTIONS ===

1. You will observe that a large portion of the terms in the dictionary are numbers. However, we normally do not use numbers as query terms to search. Do you think it is a good idea to remove these number entries from the dictionary and the postings lists? Can you propose methods to normalize these numbers? How many percentage of reduction in disk storage do you observe after removing/normalizing these numbers?

Yes it will be a good idea, since searches rarely contain numbers, it does not benefit us to index numbers. Furthermore, numbers can appear in many various formats and hence have different meanings (dates, addresses, serial codes etc).
It would be unfeasible to index all those variations with different meanings/semantics (will probably require complex use of regexing and tricks). The cost is high but the benefit is not great.

2. What do you think will happen if we remove stop words from the dictionary and postings file? How does it affect the searching phase?

The dictionary probably will not benefit from much space savings. The current dictionary has 7769 unique terms, whereas a list I found online mentions about 300 stop words, or 4%. That's not a significant saving, because the dictionary does not store the doc_ids for each term when it gets serialized.
The postings file will probably benefit alot more, since these stop words are very common and so the postings file will likely have many entries pertaining to those stop words.
For searching, if we remove the stop words we will run into problems for handling queries, for both boolean as well as phrasal. For e.g. if 'am' is a stopword, the query Hello AND I AND am will need to be processed to ignore "AND am". This is additional difficulty.

3. The NLTK tokenizer may not correctly tokenize all terms. What do you observe from the resulting terms produced by sent_tokenize() and word_tokenize()? Can you propose rules to further refine these results?

I have not done very extensive testing but I've noticed that linebreaks '\n' gets tokenized, and hyphens that occur in-between words. Both '\n' and hyphens can be easily replaced with ''. Hyphenated words are usually related, e.g. 'police-woman'. Although such words are usually one concept, it might
be good to separate the hyphenated words ie. police and woman. This will have to be done on the search side as well e.g. pretty AND police-woman will become pretty AND police AND woman
